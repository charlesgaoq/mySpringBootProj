[2019-10-16 11:03:56.371][main][INFO][org.springframework.boot.SpringApplication][597]:The following profiles are active: dev
[2019-10-16 11:03:56.415][main][INFO][org.springframework.context.support.AbstractApplicationContext][583]:Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@372ea2bc: startup date [Wed Oct 16 11:03:56 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@20bd8be5
[2019-10-16 11:03:57.650][main][INFO][org.springframework.integration.config.IntegrationRegistrar][341]:No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
[2019-10-16 11:03:58.244][main][INFO][org.springframework.data.repository.config.RepositoryConfigurationDelegate][165]:Multiple Spring Data modules found, entering strict repository configuration mode!
[2019-10-16 11:03:59.194][main][INFO][org.springframework.cloud.context.scope.GenericScope][288]:BeanFactory id=7e830820-c4cf-3f36-a00d-51d0537d67ee
[2019-10-16 11:03:59.224][main][INFO][org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor][130]:No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
[2019-10-16 11:03:59.227][main][INFO][org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor][158]:No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
[2019-10-16 11:03:59.242][main][INFO][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor][155]:JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2019-10-16 11:03:59.481][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$6826f68] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:03:59.637][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$32d05de5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:04:00.296][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'integrationGlobalProperties' of type [org.springframework.beans.factory.config.PropertiesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:04:00.304][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'integrationGlobalProperties' of type [java.util.Properties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:04:00.391][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration' of type [org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration$$EnhancerBySpringCGLIB$$64fd0426] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:04:00.431][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$4eea60e2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:04:01.449][main][INFO][org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer][92]:Tomcat initialized with port(s): 8120 (http)
[2019-10-16 11:04:01.476][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Initializing ProtocolHandler ["http-nio-8120"]
[2019-10-16 11:04:01.504][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Starting service [Tomcat]
[2019-10-16 11:04:01.505][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Starting Servlet Engine: Apache Tomcat/8.5.35
[2019-10-16 11:04:01.932][localhost-startStop-1][INFO][org.apache.juli.logging.DirectJDKLog][180]:Initializing Spring embedded WebApplicationContext
[2019-10-16 11:04:01.933][localhost-startStop-1][INFO][org.springframework.boot.context.embedded.EmbeddedWebApplicationContext][287]:Root WebApplicationContext: initialization completed in 5518 ms
[2019-10-16 11:04:03.051][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.ServletRegistrationBean][191]:Mapping servlet: 'dispatcherServlet' to [/]
[2019-10-16 11:04:03.055][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.ServletRegistrationBean][191]:Mapping servlet: 'statViewServlet' to [/druid/*]
[2019-10-16 11:04:03.064][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'metricsFilter' to: [/*]
[2019-10-16 11:04:03.065][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'characterEncodingFilter' to: [/*]
[2019-10-16 11:04:03.066][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
[2019-10-16 11:04:03.066][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'httpPutFormContentFilter' to: [/*]
[2019-10-16 11:04:03.067][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'requestContextFilter' to: [/*]
[2019-10-16 11:04:03.067][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'webRequestLoggingFilter' to: [/*]
[2019-10-16 11:04:03.068][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][272]:Mapping filter: 'webStatFilter' to urls: [/*]
[2019-10-16 11:04:03.068][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'applicationContextIdFilter' to: [/*]
[2019-10-16 11:04:03.818][main][INFO][org.springframework.scheduling.concurrent.ExecutorConfigurationSupport][166]:Initializing ExecutorService 'taskScheduler'
[2019-10-16 11:04:04.064][main][INFO][com.netflix.config.sources.URLConfigurationSource][122]:To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
[2019-10-16 11:04:04.081][main][INFO][com.netflix.config.sources.URLConfigurationSource][122]:To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
[2019-10-16 11:04:04.963][main][INFO][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter][556]:Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@372ea2bc: startup date [Wed Oct 16 11:03:56 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@20bd8be5
[2019-10-16 11:04:05.181][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
[2019-10-16 11:04:05.183][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
[2019-10-16 11:04:05.273][main][INFO][org.springframework.web.servlet.handler.AbstractUrlHandlerMapping][362]:Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
[2019-10-16 11:04:05.273][main][INFO][org.springframework.web.servlet.handler.AbstractUrlHandlerMapping][362]:Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
[2019-10-16 11:04:05.387][main][INFO][org.springframework.web.servlet.handler.AbstractUrlHandlerMapping][362]:Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
[2019-10-16 11:04:08.023][main][INFO][com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure][56]:Init DruidDataSource
[2019-10-16 11:04:09.488][main][INFO][com.alibaba.druid.pool.DruidDataSource][930]:{dataSource-1} inited
[2019-10-16 11:04:13.865][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.869][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
[2019-10-16 11:04:13.869][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.871][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
[2019-10-16 11:04:13.879][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
[2019-10-16 11:04:13.881][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
[2019-10-16 11:04:13.883][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.886][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.892][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.902][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.904][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.905][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
[2019-10-16 11:04:13.906][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
[2019-10-16 11:04:13.913][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.919][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
[2019-10-16 11:04:13.921][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
[2019-10-16 11:04:13.921][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.922][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
[2019-10-16 11:04:13.923][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
[2019-10-16 11:04:13.945][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/service-registry/instance-status],methods=[GET]}" onto public org.springframework.http.ResponseEntity org.springframework.cloud.client.serviceregistry.endpoint.ServiceRegistryEndpoint.getStatus()
[2019-10-16 11:04:13.948][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/service-registry/instance-status],methods=[POST]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.cloud.client.serviceregistry.endpoint.ServiceRegistryEndpoint.setStatus(java.lang.String)
[2019-10-16 11:04:13.950][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.951][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.952][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:13.953][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/channels || /channels.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:04:14.729][main][INFO][org.springframework.ui.freemarker.SpringTemplateLoader][61]:SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@372ea2bc: startup date [Wed Oct 16 11:03:56 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@20bd8be5] and template loader path [classpath:/templates/]
[2019-10-16 11:04:14.731][main][INFO][org.springframework.web.servlet.view.freemarker.FreeMarkerConfigurer][127]:ClassTemplateLoader for Spring macros added to FreeMarker configuration
[2019-10-16 11:04:15.702][main][INFO][org.springframework.integration.codec.kryo.CompositeKryoRegistrar][74]:configured Kryo registration [40, java.io.File] with serializer org.springframework.integration.codec.kryo.FileSerializer
[2019-10-16 11:04:15.949][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.input' has 1 subscriber(s).
[2019-10-16 11:04:15.952][main][INFO][org.springframework.jmx.export.MBeanExporter][431]:Registering beans for JMX exposure on startup
[2019-10-16 11:04:15.955][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'statFilter' has been autodetected for JMX exposure
[2019-10-16 11:04:15.956][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'dataSource' has been autodetected for JMX exposure
[2019-10-16 11:04:15.974][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'integrationMbeanExporter' has been autodetected for JMX exposure
[2019-10-16 11:04:15.976][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
[2019-10-16 11:04:15.977][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
[2019-10-16 11:04:15.979][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'environmentManager' has been autodetected for JMX exposure
[2019-10-16 11:04:15.980][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'serviceRegistryEndpoint' has been autodetected for JMX exposure
[2019-10-16 11:04:15.982][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'refreshScope' has been autodetected for JMX exposure
[2019-10-16 11:04:15.989][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
[2019-10-16 11:04:16.008][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'serviceRegistryEndpoint': registering with JMX server as MBean [org.springframework.cloud.client.serviceregistry.endpoint:name=serviceRegistryEndpoint,type=ServiceRegistryEndpoint]
[2019-10-16 11:04:16.019][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
[2019-10-16 11:04:16.050][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'integrationMbeanExporter': registering with JMX server as MBean [org.springframework.integration.monitor:name=integrationMbeanExporter,type=IntegrationMBeanExporter]
[2019-10-16 11:04:16.082][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=372ea2bc,type=ConfigurationPropertiesRebinder]
[2019-10-16 11:04:16.086][main][INFO][org.springframework.jmx.export.MBeanExporter][672]:Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
[2019-10-16 11:04:16.088][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
[2019-10-16 11:04:16.093][main][INFO][org.springframework.jmx.export.MBeanExporter][672]:Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
[2019-10-16 11:04:16.104][main][INFO][org.springframework.jmx.export.MBeanExporter][431]:Registering beans for JMX exposure on startup
[2019-10-16 11:04:16.104][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][647]:Registering MessageChannel input
[2019-10-16 11:04:16.111][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageChannel,name=input': registering with JMX server as MBean [org.springframework.integration:type=MessageChannel,name=input]
[2019-10-16 11:04:16.160][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][647]:Registering MessageChannel nullChannel
[2019-10-16 11:04:16.163][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageChannel,name=nullChannel': registering with JMX server as MBean [org.springframework.integration:type=MessageChannel,name=nullChannel]
[2019-10-16 11:04:16.184][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][647]:Registering MessageChannel errorChannel
[2019-10-16 11:04:16.187][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageChannel,name=errorChannel': registering with JMX server as MBean [org.springframework.integration:type=MessageChannel,name=errorChannel]
[2019-10-16 11:04:16.240][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][664]:Registering MessageHandler org.springframework.cloud.stream.binding.StreamListenerMessageHandler@8961e55
[2019-10-16 11:04:16.243][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageHandler,name=org.springframework.cloud.stream.binding.StreamListenerMessageHandler@8961e55,bean=handler': registering with JMX server as MBean [org.springframework.integration:type=MessageHandler,name=org.springframework.cloud.stream.binding.StreamListenerMessageHandler@8961e55,bean=handler]
[2019-10-16 11:04:16.279][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][664]:Registering MessageHandler errorLogger
[2019-10-16 11:04:16.282][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageHandler,name=errorLogger,bean=internal': registering with JMX server as MBean [org.springframework.integration:type=MessageHandler,name=errorLogger,bean=internal]
[2019-10-16 11:04:16.298][main][INFO][org.springframework.jmx.export.MBeanExporter][431]:Registering beans for JMX exposure on startup
[2019-10-16 11:04:16.326][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase -2147482648
[2019-10-16 11:04:16.331][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase 0
[2019-10-16 11:04:16.378][main][INFO][org.springframework.cloud.netflix.eureka.InstanceInfoFactory][71]:Setting initial instance status as: STARTING
[2019-10-16 11:04:16.491][main][INFO][com.netflix.discovery.DiscoveryClient][347]:Initializing Eureka in region us-east-1
[2019-10-16 11:04:17.444][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][70]:Using JSON encoding codec LegacyJacksonJson
[2019-10-16 11:04:17.445][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][71]:Using JSON decoding codec LegacyJacksonJson
[2019-10-16 11:04:17.750][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][80]:Using XML encoding codec XStreamXml
[2019-10-16 11:04:17.751][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][81]:Using XML decoding codec XStreamXml
[2019-10-16 11:04:18.915][main][INFO][com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver][43]:Resolving eureka endpoints via configuration
[2019-10-16 11:04:19.927][main][INFO][com.netflix.discovery.DiscoveryClient][934]:Disable delta property : false
[2019-10-16 11:04:19.928][main][INFO][com.netflix.discovery.DiscoveryClient][935]:Single vip registry refresh property : null
[2019-10-16 11:04:19.929][main][INFO][com.netflix.discovery.DiscoveryClient][936]:Force full registry fetch : false
[2019-10-16 11:04:19.929][main][INFO][com.netflix.discovery.DiscoveryClient][937]:Application is null : false
[2019-10-16 11:04:19.930][main][INFO][com.netflix.discovery.DiscoveryClient][938]:Registered Applications size is zero : true
[2019-10-16 11:04:19.930][main][INFO][com.netflix.discovery.DiscoveryClient][940]:Application version is -1: true
[2019-10-16 11:04:19.931][main][INFO][com.netflix.discovery.DiscoveryClient][1023]:Getting all instance registry info from the eureka server
[2019-10-16 11:04:20.482][main][INFO][com.netflix.discovery.DiscoveryClient][1032]:The response status is 200
[2019-10-16 11:04:20.492][main][INFO][com.netflix.discovery.DiscoveryClient][1258]:Starting heartbeat executor: renew interval is: 30
[2019-10-16 11:04:20.499][main][INFO][com.netflix.discovery.InstanceInfoReplicator][59]:InstanceInfoReplicator onDemand update allowed rate per min is 4
[2019-10-16 11:04:20.505][main][INFO][com.netflix.discovery.DiscoveryClient][434]:Discovery Client initialized at timestamp 1571195060505 with initial instances count: 7
[2019-10-16 11:04:20.532][main][INFO][org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry][40]:Registering application kafkatobase with eureka with status UP
[2019-10-16 11:04:20.534][main][INFO][com.netflix.discovery.DiscoveryClient$3][1293]:Saw local status change event StatusChangeEvent [timestamp=1571195060534, current=UP, previous=STARTING]
[2019-10-16 11:04:20.541][DiscoveryClient-InstanceInfoReplicator-0][INFO][com.netflix.discovery.DiscoveryClient][804]:DiscoveryClient_KAFKATOBASE/10.0.8.217:kafkatobase:8120: registering service...
[2019-10-16 11:04:20.561][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'auditEventsEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=auditEventsEndpoint]
[2019-10-16 11:04:20.596][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'archaiusEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=archaiusEndpoint]
[2019-10-16 11:04:20.609][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'featuresEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=featuresEndpoint]
[2019-10-16 11:04:20.619][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'requestMappingEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=requestMappingEndpoint]
[2019-10-16 11:04:20.623][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'environmentEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=environmentEndpoint]
[2019-10-16 11:04:20.627][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'healthEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=healthEndpoint]
[2019-10-16 11:04:20.679][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'beansEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=beansEndpoint]
[2019-10-16 11:04:20.684][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'infoEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=infoEndpoint]
[2019-10-16 11:04:20.688][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'loggersEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=loggersEndpoint]
[2019-10-16 11:04:20.706][DiscoveryClient-InstanceInfoReplicator-0][INFO][com.netflix.discovery.DiscoveryClient][813]:DiscoveryClient_KAFKATOBASE/10.0.8.217:kafkatobase:8120 - registration status: 204
[2019-10-16 11:04:20.710][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'metricsEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=metricsEndpoint]
[2019-10-16 11:04:20.715][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'traceEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=traceEndpoint]
[2019-10-16 11:04:20.719][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'dumpEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=dumpEndpoint]
[2019-10-16 11:04:20.724][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'autoConfigurationReportEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=autoConfigurationReportEndpoint]
[2019-10-16 11:04:20.728][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'configurationPropertiesReportEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=configurationPropertiesReportEndpoint]
[2019-10-16 11:04:20.732][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'channelsEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=channelsEndpoint]
[2019-10-16 11:04:20.734][main][INFO][org.springframework.integration.endpoint.EventDrivenConsumer][108]:Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
[2019-10-16 11:04:20.735][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.errorChannel' has 1 subscriber(s).
[2019-10-16 11:04:20.735][main][INFO][org.springframework.integration.endpoint.AbstractEndpoint][120]:started _org.springframework.integration.errorLogger
[2019-10-16 11:04:20.735][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase 2147482647
[2019-10-16 11:04:22.184][main][INFO][org.springframework.boot.SpringApplication][597]:The following profiles are active: dev
[2019-10-16 11:04:22.196][main][INFO][org.springframework.context.support.AbstractApplicationContext][583]:Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@386ec37d: startup date [Wed Oct 16 11:04:22 CST 2019]; parent: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@372ea2bc
[2019-10-16 11:04:22.240][main][INFO][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor][155]:JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2019-10-16 11:04:22.317][main][INFO][org.springframework.cloud.stream.binder.kafka.config.KafkaBinderConfiguration][155]:AdminUtils selected: Kafka 0.10 AdminUtils
[2019-10-16 11:04:22.408][main][INFO][org.springframework.boot.StartupInfoLogger][57]:Started KafkaToHabseApp in 1.588 seconds (JVM running for 31.591)
[2019-10-16 11:04:23.055][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT
[2019-10-16 11:04:23.055][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:host.name=chance-PC
[2019-10-16 11:04:23.056][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.version=1.8.0_131
[2019-10-16 11:04:23.056][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.vendor=Oracle Corporation
[2019-10-16 11:04:23.056][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre
[2019-10-16 11:04:23.056][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.class.path=D:\workspace-sts-3.9.6.RELEASE\kafkatohbase\target\classes;D:\workspace-sts-3.9.6.RELEASE\wisdom-policing-domain\target\classes;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-stream-kafka\1.3.2.RELEASE\spring-cloud-starter-stream-kafka-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream-binder-kafka\1.3.2.RELEASE\spring-cloud-stream-binder-kafka-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream-binder-kafka-core\1.3.2.RELEASE\spring-cloud-stream-binder-kafka-core-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-kafka\2.1.2.RELEASE\spring-integration-kafka-2.1.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream\1.3.2.RELEASE\spring-cloud-stream-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-actuator\1.5.18.RELEASE\spring-boot-starter-actuator-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-actuator\1.5.18.RELEASE\spring-boot-actuator-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-validation\1.5.18.RELEASE\spring-boot-starter-validation-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-messaging\4.3.21.RELEASE\spring-messaging-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-core\4.3.18.RELEASE\spring-integration-core-4.3.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-jmx\4.3.18.RELEASE\spring-integration-jmx-4.3.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-tuple\1.0.0.RELEASE\spring-tuple-1.0.0.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-tuple\1.0.0.RELEASE\spring-integration-tuple-1.0.0.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\retry\spring-retry\1.2.2.RELEASE\spring-retry-1.2.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream-codec\1.3.2.RELEASE\spring-cloud-stream-codec-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\myRepository\m2\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\myRepository\m2\repository\org\apache\kafka\kafka_2.11\0.10.1.1\kafka_2.11-0.10.1.1.jar;D:\myRepository\m2\repository\net\sf\jopt-simple\jopt-simple\4.9\jopt-simple-4.9.jar;D:\myRepository\m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\myRepository\m2\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\myRepository\m2\repository\com\101tec\zkclient\0.9\zkclient-0.9.jar;D:\myRepository\m2\repository\org\apache\zookeeper\zookeeper\3.4.8\zookeeper-3.4.8.jar;D:\myRepository\m2\repository\io\netty\netty\3.7.0.Final\netty-3.7.0.Final.jar;D:\myRepository\m2\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.4\scala-parser-combinators_2.11-1.0.4.jar;D:\myRepository\m2\repository\org\springframework\kafka\spring-kafka\1.1.8.RELEASE\spring-kafka-1.1.8.RELEASE.jar;D:\myRepository\m2\repository\org\apache\kafka\kafka-clients\0.10.1.0\kafka-clients-0.10.1.0.jar;D:\myRepository\m2\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\myRepository\m2\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\myRepository\m2\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-web\1.5.18.RELEASE\spring-boot-starter-web-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-tomcat\1.5.18.RELEASE\spring-boot-starter-tomcat-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\apache\tomcat\embed\tomcat-embed-core\8.5.35\tomcat-embed-core-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\tomcat-annotations-api\8.5.35\tomcat-annotations-api-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\embed\tomcat-embed-el\8.5.35\tomcat-embed-el-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\8.5.35\tomcat-embed-websocket-8.5.35.jar;D:\myRepository\m2\repository\org\hibernate\hibernate-validator\5.3.6.Final\hibernate-validator-5.3.6.Final.jar;D:\myRepository\m2\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\myRepository\m2\repository\org\jboss\logging\jboss-logging\3.3.2.Final\jboss-logging-3.3.2.Final.jar;D:\myRepository\m2\repository\com\fasterxml\classmate\1.3.4\classmate-1.3.4.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\core\jackson-databind\2.8.11.3\jackson-databind-2.8.11.3.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.8.0\jackson-annotations-2.8.0.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\core\jackson-core\2.8.11\jackson-core-2.8.11.jar;D:\myRepository\m2\repository\org\springframework\spring-web\4.3.21.RELEASE\spring-web-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-aop\4.3.21.RELEASE\spring-aop-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-beans\4.3.21.RELEASE\spring-beans-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-context\4.3.21.RELEASE\spring-context-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-webmvc\4.3.21.RELEASE\spring-webmvc-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-expression\4.3.21.RELEASE\spring-expression-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-eureka\1.4.4.RELEASE\spring-cloud-starter-eureka-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-eureka-client\1.4.4.RELEASE\spring-cloud-starter-netflix-eureka-client-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter\1.3.3.RELEASE\spring-cloud-starter-1.3.3.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-context\1.3.3.RELEASE\spring-cloud-context-1.3.3.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\security\spring-security-crypto\4.2.10.RELEASE\spring-security-crypto-4.2.10.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-commons\1.3.3.RELEASE\spring-cloud-commons-1.3.3.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\security\spring-security-rsa\1.0.3.RELEASE\spring-security-rsa-1.0.3.RELEASE.jar;D:\myRepository\m2\repository\org\bouncycastle\bcpkix-jdk15on\1.55\bcpkix-jdk15on-1.55.jar;D:\myRepository\m2\repository\org\bouncycastle\bcprov-jdk15on\1.55\bcprov-jdk15on-1.55.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-netflix-core\1.4.4.RELEASE\spring-cloud-netflix-core-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-netflix-eureka-client\1.4.4.RELEASE\spring-cloud-netflix-eureka-client-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\com\netflix\eureka\eureka-client\1.7.2\eureka-client-1.7.2.jar;D:\myRepository\m2\repository\org\codehaus\jettison\jettison\1.3.7\jettison-1.3.7.jar;D:\myRepository\m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-eventbus\0.3.0\netflix-eventbus-0.3.0.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-infix\0.3.0\netflix-infix-0.3.0.jar;D:\myRepository\m2\repository\commons-jxpath\commons-jxpath\1.3\commons-jxpath-1.3.jar;D:\myRepository\m2\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;D:\myRepository\m2\repository\org\antlr\antlr-runtime\3.4\antlr-runtime-3.4.jar;D:\myRepository\m2\repository\org\antlr\stringtemplate\3.2.1\stringtemplate-3.2.1.jar;D:\myRepository\m2\repository\antlr\antlr\2.7.7\antlr-2.7.7.jar;D:\myRepository\m2\repository\com\google\code\gson\gson\2.8.5\gson-2.8.5.jar;D:\myRepository\m2\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;D:\myRepository\m2\repository\com\netflix\archaius\archaius-core\0.7.4\archaius-core-0.7.4.jar;D:\myRepository\m2\repository\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\myRepository\m2\repository\com\netflix\servo\servo-core\0.10.1\servo-core-0.10.1.jar;D:\myRepository\m2\repository\com\netflix\servo\servo-internal\0.10.1\servo-internal-0.10.1.jar;D:\myRepository\m2\repository\com\sun\jersey\jersey-core\1.19.1\jersey-core-1.19.1.jar;D:\myRepository\m2\repository\com\sun\jersey\jersey-client\1.19.1\jersey-client-1.19.1.jar;D:\myRepository\m2\repository\com\sun\jersey\contribs\jersey-apache-client4\1.19.1\jersey-apache-client4-1.19.1.jar;D:\myRepository\m2\repository\org\apache\httpcomponents\httpclient\4.5.6\httpclient-4.5.6.jar;D:\myRepository\m2\repository\org\apache\httpcomponents\httpcore\4.4.10\httpcore-4.4.10.jar;D:\myRepository\m2\repository\com\google\inject\guice\4.1.0\guice-4.1.0.jar;D:\myRepository\m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\myRepository\m2\repository\com\netflix\eureka\eureka-core\1.7.2\eureka-core-1.7.2.jar;D:\myRepository\m2\repository\org\codehaus\woodstox\woodstox-core-asl\4.4.1\woodstox-core-asl-4.4.1.jar;D:\myRepository\m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\myRepository\m2\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-archaius\1.4.4.RELEASE\spring-cloud-starter-netflix-archaius-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\commons-configuration\commons-configuration\1.8\commons-configuration-1.8.jar;D:\myRepository\m2\repository\com\google\guava\guava\18.0\guava-18.0.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-ribbon\1.4.4.RELEASE\spring-cloud-starter-netflix-ribbon-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon\2.2.5\ribbon-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-transport\2.2.5\ribbon-transport-2.2.5.jar;D:\myRepository\m2\repository\io\reactivex\rxnetty-contexts\0.4.9\rxnetty-contexts-0.4.9.jar;D:\myRepository\m2\repository\io\reactivex\rxnetty-servo\0.4.9\rxnetty-servo-0.4.9.jar;D:\myRepository\m2\repository\io\reactivex\rxnetty\0.4.9\rxnetty-0.4.9.jar;D:\myRepository\m2\repository\io\netty\netty-codec-http\4.0.27.Final\netty-codec-http-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-codec\4.0.27.Final\netty-codec-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-handler\4.0.27.Final\netty-handler-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-transport-native-epoll\4.0.27.Final\netty-transport-native-epoll-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-common\4.0.27.Final\netty-common-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-buffer\4.0.27.Final\netty-buffer-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-transport\4.0.27.Final\netty-transport-4.0.27.Final.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-core\2.2.5\ribbon-core-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-httpclient\2.2.5\ribbon-httpclient-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-commons-util\0.1.1\netflix-commons-util-0.1.1.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-loadbalancer\2.2.5\ribbon-loadbalancer-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-statistics\0.1.1\netflix-statistics-0.1.1.jar;D:\myRepository\m2\repository\io\reactivex\rxjava\1.2.0\rxjava-1.2.0.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-eureka\2.2.5\ribbon-eureka-2.2.5.jar;D:\myRepository\m2\repository\com\thoughtworks\xstream\xstream\1.4.10\xstream-1.4.10.jar;D:\myRepository\m2\repository\xmlpull\xmlpull\1.1.3.1\xmlpull-1.1.3.1.jar;D:\myRepository\m2\repository\xpp3\xpp3_min\1.1.4c\xpp3_min-1.1.4c.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-eureka-server\1.4.4.RELEASE\spring-cloud-starter-eureka-server-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-eureka-server\1.4.4.RELEASE\spring-cloud-starter-netflix-eureka-server-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-netflix-eureka-server\1.4.4.RELEASE\spring-cloud-netflix-eureka-server-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-freemarker\1.5.18.RELEASE\spring-boot-starter-freemarker-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\freemarker\freemarker\2.3.28\freemarker-2.3.28.jar;D:\myRepository\m2\repository\com\sun\jersey\jersey-server\1.19.1\jersey-server-1.19.1.jar;D:\myRepository\m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-xml\2.8.11\jackson-dataformat-xml-2.8.11.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.8.11\jackson-module-jaxb-annotations-2.8.11.jar;D:\myRepository\m2\repository\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\myRepository\m2\repository\org\ow2\asm\asm\5.0.3\asm-5.0.3.jar;D:\myRepository\m2\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\myRepository\m2\repository\org\springframework\spring-core\4.3.21.RELEASE\spring-core-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\com\alibaba\druid-spring-boot-starter\1.1.10\druid-spring-boot-starter-1.1.10.jar;D:\myRepository\m2\repository\com\alibaba\druid\1.1.10\druid-1.1.10.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-autoconfigure\1.5.18.RELEASE\spring-boot-autoconfigure-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\mysql\mysql-connector-java\5.1.47\mysql-connector-java-5.1.47.jar;D:\myRepository\m2\repository\com\github\pagehelper\pagehelper-spring-boot-starter\1.2.5\pagehelper-spring-boot-starter-1.2.5.jar;D:\myRepository\m2\repository\com\github\pagehelper\pagehelper-spring-boot-autoconfigure\1.2.5\pagehelper-spring-boot-autoconfigure-1.2.5.jar;D:\myRepository\m2\repository\com\github\pagehelper\pagehelper\5.1.4\pagehelper-5.1.4.jar;D:\myRepository\m2\repository\com\github\jsqlparser\jsqlparser\1.0\jsqlparser-1.0.jar;D:\myRepository\m2\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\1.3.2\mybatis-spring-boot-starter-1.3.2.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-jdbc\1.5.18.RELEASE\spring-boot-starter-jdbc-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\apache\tomcat\tomcat-jdbc\8.5.35\tomcat-jdbc-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\tomcat-juli\8.5.35\tomcat-juli-8.5.35.jar;D:\myRepository\m2\repository\org\springframework\spring-jdbc\4.3.21.RELEASE\spring-jdbc-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\1.3.2\mybatis-spring-boot-autoconfigure-1.3.2.jar;D:\myRepository\m2\repository\org\mybatis\mybatis\3.4.6\mybatis-3.4.6.jar;D:\myRepository\m2\repository\org\mybatis\mybatis-spring\1.3.2\mybatis-spring-1.3.2.jar;D:\myRepository\m2\repository\com\eversec\ebp\system\system-feignclient\1.1.0\system-feignclient-1.1.0.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-ribbon\1.4.4.RELEASE\spring-cloud-starter-ribbon-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-feign\1.4.4.RELEASE\spring-cloud-starter-feign-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-openfeign\1.4.4.RELEASE\spring-cloud-starter-openfeign-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\io\github\openfeign\feign-core\9.5.0\feign-core-9.5.0.jar;D:\myRepository\m2\repository\org\jvnet\animal-sniffer-annotation\1.0\animal-sniffer-annotation-1.0.jar;D:\myRepository\m2\repository\io\github\openfeign\feign-slf4j\9.5.0\feign-slf4j-9.5.0.jar;D:\myRepository\m2\repository\io\github\openfeign\feign-hystrix\9.5.0\feign-hystrix-9.5.0.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-hystrix\1.4.4.RELEASE\spring-cloud-starter-hystrix-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-hystrix\1.4.4.RELEASE\spring-cloud-starter-netflix-hystrix-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-core\1.5.12\hystrix-core-1.5.12.jar;D:\myRepository\m2\repository\org\hdrhistogram\HdrHistogram\2.1.9\HdrHistogram-2.1.9.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-metrics-event-stream\1.5.12\hystrix-metrics-event-stream-1.5.12.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-serialization\1.5.12\hystrix-serialization-1.5.12.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\module\jackson-module-afterburner\2.8.11\jackson-module-afterburner-2.8.11.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-javanica\1.5.12\hystrix-javanica-1.5.12.jar;D:\myRepository\m2\repository\org\aspectj\aspectjweaver\1.8.13\aspectjweaver-1.8.13.jar;D:\myRepository\m2\repository\com\eversec\framework\eversec-web\1.0.0-SNAPSHOT\eversec-web-1.0.0-SNAPSHOT.jar;D:\myRepository\m2\repository\com\eversec\framework\eversec-core\1.0.0-SNAPSHOT\eversec-core-1.0.0-SNAPSHOT.jar;D:\myRepository\m2\repository\com\alibaba\fastjson\1.2.58\fastjson-1.2.58.jar;D:\myRepository\m2\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;D:\myRepository\m2\repository\xml-apis\xml-apis\1.4.01\xml-apis-1.4.01.jar;D:\myRepository\m2\repository\jaxen\jaxen\1.1.6\jaxen-1.1.6.jar;D:\myRepository\m2\repository\com\eversec\framework\eversec-commons\1.0.0-SNAPSHOT\eversec-commons-1.0.0-SNAPSHOT.jar;D:\myRepository\m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\myRepository\m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\myRepository\m2\repository\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\myRepository\m2\repository\commons-codec\commons-codec\1.10\commons-codec-1.10.jar;D:\myRepository\m2\repository\io\springfox\springfox-swagger-ui\2.7.0\springfox-swagger-ui-2.7.0.jar;D:\myRepository\m2\repository\io\springfox\springfox-spring-web\2.7.0\springfox-spring-web-2.7.0.jar;D:\myRepository\m2\repository\org\reflections\reflections\0.9.11\reflections-0.9.11.jar;D:\myRepository\m2\repository\org\javassist\javassist\3.21.0-GA\javassist-3.21.0-GA.jar;D:\myRepository\m2\repository\io\springfox\springfox-swagger2\2.7.0\springfox-swagger2-2.7.0.jar;D:\myRepository\m2\repository\io\swagger\swagger-models\1.5.13\swagger-models-1.5.13.jar;D:\myRepository\m2\repository\io\springfox\springfox-spi\2.7.0\springfox-spi-2.7.0.jar;D:\myRepository\m2\repository\io\springfox\springfox-core\2.7.0\springfox-core-2.7.0.jar;D:\myRepository\m2\repository\net\bytebuddy\byte-buddy\1.6.14\byte-buddy-1.6.14.jar;D:\myRepository\m2\repository\io\springfox\springfox-schema\2.7.0\springfox-schema-2.7.0.jar;D:\myRepository\m2\repository\io\springfox\springfox-swagger-common\2.7.0\springfox-swagger-common-2.7.0.jar;D:\myRepository\m2\repository\org\springframework\plugin\spring-plugin-core\1.2.0.RELEASE\spring-plugin-core-1.2.0.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\plugin\spring-plugin-metadata\1.2.0.RELEASE\spring-plugin-metadata-1.2.0.RELEASE.jar;D:\myRepository\m2\repository\org\mapstruct\mapstruct\1.1.0.Final\mapstruct-1.1.0.Final.jar;D:\myRepository\m2\repository\com\eversec\ebp\system\system-api\1.1.0\system-api-1.1.0.jar;D:\myRepository\m2\repository\org\hibernate\javax\persistence\hibernate-jpa-2.1-api\1.0.0.Final\hibernate-jpa-2.1-api-1.0.0.Final.jar;D:\myRepository\m2\repository\io\swagger\swagger-annotations\1.5.13\swagger-annotations-1.5.13.jar;D:\myRepository\m2\repository\org\apache\commons\commons-lang3\3.8.1\commons-lang3-3.8.1.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-log4j2\1.5.18.RELEASE\spring-boot-starter-log4j2-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-slf4j-impl\2.7\log4j-slf4j-impl-2.7.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-api\2.7\log4j-api-2.7.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-core\2.7\log4j-core-2.7.jar;D:\myRepository\m2\repository\org\slf4j\jcl-over-slf4j\1.7.25\jcl-over-slf4j-1.7.25.jar;D:\myRepository\m2\repository\org\slf4j\jul-to-slf4j\1.7.25\jul-to-slf4j-1.7.25.jar;D:\myRepository\m2\repository\com\lmax\disruptor\3.3.8\disruptor-3.3.8.jar;D:\myRepository\m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-data-redis\1.5.18.RELEASE\spring-boot-starter-data-redis-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\data\spring-data-redis\1.8.17.RELEASE\spring-data-redis-1.8.17.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\data\spring-data-keyvalue\1.2.17.RELEASE\spring-data-keyvalue-1.2.17.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\data\spring-data-commons\1.13.17.RELEASE\spring-data-commons-1.13.17.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-tx\4.3.21.RELEASE\spring-tx-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-oxm\4.3.21.RELEASE\spring-oxm-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-context-support\4.3.21.RELEASE\spring-context-support-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\redis\clients\jedis\2.9.0\jedis-2.9.0.jar;D:\myRepository\m2\repository\org\apache\commons\commons-pool2\2.4.3\commons-pool2-2.4.3.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter\1.5.18.RELEASE\spring-boot-starter-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot\1.5.18.RELEASE\spring-boot-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\yaml\snakeyaml\1.17\snakeyaml-1.17.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-web\2.10.0\log4j-web-2.10.0.jar
[2019-10-16 11:04:23.059][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jdk1.8.0_131/bin/../jre/bin/server;C:/Program Files/Java/jdk1.8.0_131/bin/../jre/bin;C:/Program Files/Java/jdk1.8.0_131/bin/../jre/lib/amd64;C:\Python\Python37-32\Scripts\;C:\Python\Python37-32\;C:\Program Files\Java\jdk1.8.0_131\bin;C:\ProgramData\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Lenovo\Fingerprint Manager Pro\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\apache-maven-3.6.0\bin;C:\Program Files\nodejs\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\MySQL\MySQL Server 5.5\bin;C:\Program Files\IDM Computer Solutions\UltraEdit;C:\Program Files\Pandoc\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Microsoft VS Code Insiders\bin;C:\Users\eversec\AppData\Roaming\npm;D:\software\sts-bundle\sts-3.9.6.RELEASE;;.
[2019-10-16 11:04:23.060][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.io.tmpdir=C:\Users\eversec\AppData\Local\Temp\
[2019-10-16 11:04:23.060][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.compiler=<NA>
[2019-10-16 11:04:23.061][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:os.name=Windows 7
[2019-10-16 11:04:23.061][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:os.arch=amd64
[2019-10-16 11:04:23.061][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:os.version=6.1
[2019-10-16 11:04:23.061][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:user.name=eversec
[2019-10-16 11:04:23.062][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:user.home=C:\Users\eversec
[2019-10-16 11:04:23.062][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:user.dir=D:\workspace-sts-3.9.6.RELEASE\kafkatohbase
[2019-10-16 11:04:23.064][main][INFO][org.apache.zookeeper.ZooKeeper][438]:Initiating client connection, connectString=10.0.10.43:2181,10.0.10.44:2181,10.0.10.45:2181 sessionTimeout=10000 watcher=org.I0Itec.zkclient.ZkClient@363751f2
[2019-10-16 11:04:23.199][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1032]:Opening socket connection to server 10.0.10.44/10.0.10.44:2181. Will not attempt to authenticate using SASL (unknown error)
[2019-10-16 11:04:23.272][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][876]:Socket connection established to 10.0.10.44/10.0.10.44:2181, initiating session
[2019-10-16 11:04:23.475][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1299]:Session establishment complete on server 10.0.10.44/10.0.10.44:2181, sessionid = 0x26dcec562cf000c, negotiated timeout = 10000
[2019-10-16 11:04:24.927][main][INFO][org.apache.zookeeper.ZooKeeper][684]:Session: 0x26dcec562cf000c closed
[2019-10-16 11:04:24.927][main-EventThread][INFO][org.apache.zookeeper.ClientCnxn$EventThread][519]:EventThread shut down for session: 0x26dcec562cf000c
[2019-10-16 11:04:24.928][main][INFO][org.apache.zookeeper.ZooKeeper][438]:Initiating client connection, connectString=10.0.10.43:2181,10.0.10.44:2181,10.0.10.45:2181 sessionTimeout=10000 watcher=org.I0Itec.zkclient.ZkClient@63c31664
[2019-10-16 11:04:24.934][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1032]:Opening socket connection to server 10.0.10.44/10.0.10.44:2181. Will not attempt to authenticate using SASL (unknown error)
[2019-10-16 11:04:24.937][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][876]:Socket connection established to 10.0.10.44/10.0.10.44:2181, initiating session
[2019-10-16 11:04:24.969][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1299]:Session establishment complete on server 10.0.10.44/10.0.10.44:2181, sessionid = 0x26dcec562cf000d, negotiated timeout = 10000
[2019-10-16 11:04:25.187][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.202][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.295][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.295][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.513][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.s1mme-s1u-cdr.wisdom-policing.errors' has 1 subscriber(s).
[2019-10-16 11:04:25.516][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.s1mme-s1u-cdr.wisdom-policing.errors' has 0 subscriber(s).
[2019-10-16 11:04:25.516][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.s1mme-s1u-cdr.wisdom-policing.errors' has 1 subscriber(s).
[2019-10-16 11:04:25.517][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.s1mme-s1u-cdr.wisdom-policing.errors' has 2 subscriber(s).
[2019-10-16 11:04:25.530][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.532][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.571][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.571][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.580][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.582][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.590][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.591][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.592][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.593][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-4
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.609][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.610][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.611][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.612][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-5
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.622][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.623][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.624][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.625][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-6
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.636][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.636][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.639][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.640][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-7
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.649][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.650][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.651][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.652][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-8
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.662][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.663][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.664][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.665][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-9
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.675][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.675][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.676][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.677][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-10
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.731][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.749][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.751][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.752][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-11
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.766][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.767][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.773][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.775][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-12
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.788][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.789][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.798][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.799][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-13
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.821][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.822][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.837][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.841][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-14
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.865][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.865][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.867][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.869][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-15
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.885][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.885][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.894][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.895][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-16
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.911][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.912][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.918][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.919][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-17
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.929][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.929][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.941][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.942][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-18
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.960][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.963][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:25.970][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.971][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-19
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:25.990][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:25.995][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:26.003][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:26.004][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-20
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:26.091][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:26.091][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:26.101][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:26.102][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-21
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = wisdom-policing
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:04:26.125][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:04:26.125][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:04:26.132][main][INFO][org.springframework.integration.endpoint.AbstractEndpoint][120]:started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@445265b0
[2019-10-16 11:04:26.133][main][INFO][org.springframework.integration.endpoint.EventDrivenConsumer][108]:Adding {message-handler:inbound.s1mme-s1u-cdr.wisdom-policing} as a subscriber to the 'bridge.s1mme-s1u-cdr' channel
[2019-10-16 11:04:26.134][main][INFO][org.springframework.integration.endpoint.AbstractEndpoint][120]:started inbound.s1mme-s1u-cdr.wisdom-policing
[2019-10-16 11:04:26.136][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase 2147483647
[2019-10-16 11:04:26.171][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Starting ProtocolHandler ["http-nio-8120"]
[2019-10-16 11:04:26.194][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Using a shared selector for servlet write/read
[2019-10-16 11:04:26.657][main][INFO][org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer][216]:Tomcat started on port(s): 8120 (http)
[2019-10-16 11:04:26.658][main][INFO][org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration][124]:Updating port to 8120
[2019-10-16 11:04:26.663][main][INFO][org.springframework.boot.StartupInfoLogger][57]:Started KafkaToHabseApp in 34.289 seconds (JVM running for 35.846)
[2019-10-16 11:04:26.669][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.674][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.675][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.689][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.705][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.707][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.710][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.710][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.711][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.715][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.718][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.718][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.718][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.733][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.734][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.734][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.737][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.739][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.739][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.739][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.758][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.764][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.768][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.769][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.769][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.771][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.774][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.775][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.776][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.776][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.776][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.777][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.780][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.780][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.780][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.780][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.781][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.784][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.788][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.788][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.786][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.788][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.785][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.788][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.791][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.791][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.791][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.784][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.791][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.792][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.794][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.794][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.794][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.794][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.795][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.795][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.815][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.816][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.816][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.817][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.817][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.817][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.817][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.817][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.817][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.818][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.823][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.823][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.823][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.838][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.838][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.838][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.839][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.842][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.842][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.842][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:26.885][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.45:6667 (id: 2147482644 rack: null) for group wisdom-policing.
[2019-10-16 11:04:26.887][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:26.888][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:04:26.888][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group wisdom-policing
[2019-10-16 11:04:30.179][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.179][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.180][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.181][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.181][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.192][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.192][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.193][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.193][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.185][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.194][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-10] for group wisdom-policing
[2019-10-16 11:04:30.181][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.195][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.185][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.202][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-0] for group wisdom-policing
[2019-10-16 11:04:30.185][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.203][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-19] for group wisdom-policing
[2019-10-16 11:04:30.184][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.182][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.184][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.205][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.206][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.183][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.181][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.183][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.183][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.183][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.214][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-16] for group wisdom-policing
[2019-10-16 11:04:30.182][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.215][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-13] for group wisdom-policing
[2019-10-16 11:04:30.215][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.215][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.216][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.216][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.182][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.182][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group wisdom-policing with generation 79
[2019-10-16 11:04:30.181][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.218][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.213][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-7] for group wisdom-policing
[2019-10-16 11:04:30.211][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-14] for group wisdom-policing
[2019-10-16 11:04:30.194][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-4] for group wisdom-policing
[2019-10-16 11:04:30.192][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.220][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-2] for group wisdom-policing
[2019-10-16 11:04:30.238][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.239][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.243][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [s1mme-s1u-cdr-8] for group wisdom-policing
[2019-10-16 11:04:30.245][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.245][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group wisdom-policing
[2019-10-16 11:04:30.245][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.245][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:04:30.380][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-2]
[2019-10-16 11:04:30.380][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-13]
[2019-10-16 11:04:30.380][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-14]
[2019-10-16 11:04:30.380][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-19]
[2019-10-16 11:04:30.381][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-0]
[2019-10-16 11:04:30.382][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-4]
[2019-10-16 11:04:30.382][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-16]
[2019-10-16 11:04:30.382][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-8]
[2019-10-16 11:04:30.385][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-10]
[2019-10-16 11:04:30.401][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[s1mme-s1u-cdr-7]
[2019-10-16 11:11:39.927][main][INFO][org.springframework.boot.SpringApplication][597]:The following profiles are active: dev
[2019-10-16 11:11:39.967][main][INFO][org.springframework.context.support.AbstractApplicationContext][583]:Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@216914: startup date [Wed Oct 16 11:11:39 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5398edd0
[2019-10-16 11:11:42.152][main][INFO][org.springframework.integration.config.IntegrationRegistrar][341]:No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
[2019-10-16 11:11:43.063][main][INFO][org.springframework.data.repository.config.RepositoryConfigurationDelegate][165]:Multiple Spring Data modules found, entering strict repository configuration mode!
[2019-10-16 11:11:44.188][main][INFO][org.springframework.cloud.context.scope.GenericScope][288]:BeanFactory id=7e830820-c4cf-3f36-a00d-51d0537d67ee
[2019-10-16 11:11:44.233][main][INFO][org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor][130]:No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
[2019-10-16 11:11:44.238][main][INFO][org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor][158]:No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
[2019-10-16 11:11:44.272][main][INFO][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor][155]:JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2019-10-16 11:11:45.085][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$7709d174] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:11:45.332][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$a357bff1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:11:45.991][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'integrationGlobalProperties' of type [org.springframework.beans.factory.config.PropertiesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:11:46.002][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'integrationGlobalProperties' of type [java.util.Properties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:11:46.140][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration' of type [org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration$$EnhancerBySpringCGLIB$$d5846632] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:11:46.210][main][INFO][org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker][327]:Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$bf71c2ee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
[2019-10-16 11:11:47.691][main][INFO][org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer][92]:Tomcat initialized with port(s): 8120 (http)
[2019-10-16 11:11:47.724][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Initializing ProtocolHandler ["http-nio-8120"]
[2019-10-16 11:11:47.756][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Starting service [Tomcat]
[2019-10-16 11:11:47.759][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Starting Servlet Engine: Apache Tomcat/8.5.35
[2019-10-16 11:11:48.363][localhost-startStop-1][INFO][org.apache.juli.logging.DirectJDKLog][180]:Initializing Spring embedded WebApplicationContext
[2019-10-16 11:11:48.364][localhost-startStop-1][INFO][org.springframework.boot.context.embedded.EmbeddedWebApplicationContext][287]:Root WebApplicationContext: initialization completed in 8396 ms
[2019-10-16 11:11:49.973][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.ServletRegistrationBean][191]:Mapping servlet: 'dispatcherServlet' to [/]
[2019-10-16 11:11:49.975][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.ServletRegistrationBean][191]:Mapping servlet: 'statViewServlet' to [/druid/*]
[2019-10-16 11:11:49.983][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'metricsFilter' to: [/*]
[2019-10-16 11:11:49.984][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'characterEncodingFilter' to: [/*]
[2019-10-16 11:11:49.985][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
[2019-10-16 11:11:49.985][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'httpPutFormContentFilter' to: [/*]
[2019-10-16 11:11:49.986][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'requestContextFilter' to: [/*]
[2019-10-16 11:11:49.986][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'webRequestLoggingFilter' to: [/*]
[2019-10-16 11:11:49.987][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][272]:Mapping filter: 'webStatFilter' to urls: [/*]
[2019-10-16 11:11:49.987][localhost-startStop-1][INFO][org.springframework.boot.web.servlet.AbstractFilterRegistrationBean][259]:Mapping filter: 'applicationContextIdFilter' to: [/*]
[2019-10-16 11:11:51.330][main][INFO][org.springframework.scheduling.concurrent.ExecutorConfigurationSupport][166]:Initializing ExecutorService 'taskScheduler'
[2019-10-16 11:11:51.646][main][INFO][com.netflix.config.sources.URLConfigurationSource][122]:To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
[2019-10-16 11:11:51.662][main][INFO][com.netflix.config.sources.URLConfigurationSource][122]:To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
[2019-10-16 11:11:52.784][main][INFO][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter][556]:Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@216914: startup date [Wed Oct 16 11:11:39 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5398edd0
[2019-10-16 11:11:53.080][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
[2019-10-16 11:11:53.083][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
[2019-10-16 11:11:53.266][main][INFO][org.springframework.web.servlet.handler.AbstractUrlHandlerMapping][362]:Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
[2019-10-16 11:11:53.267][main][INFO][org.springframework.web.servlet.handler.AbstractUrlHandlerMapping][362]:Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
[2019-10-16 11:11:53.529][main][INFO][org.springframework.web.servlet.handler.AbstractUrlHandlerMapping][362]:Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
[2019-10-16 11:11:56.479][main][INFO][com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure][56]:Init DruidDataSource
[2019-10-16 11:11:57.853][main][INFO][com.alibaba.druid.pool.DruidDataSource][930]:{dataSource-1} inited
[2019-10-16 11:12:00.871][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/service-registry/instance-status],methods=[POST]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.cloud.client.serviceregistry.endpoint.ServiceRegistryEndpoint.setStatus(java.lang.String)
[2019-10-16 11:12:00.872][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/service-registry/instance-status],methods=[GET]}" onto public org.springframework.http.ResponseEntity org.springframework.cloud.client.serviceregistry.endpoint.ServiceRegistryEndpoint.getStatus()
[2019-10-16 11:12:00.874][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
[2019-10-16 11:12:00.881][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
[2019-10-16 11:12:00.883][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.888][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.893][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
[2019-10-16 11:12:00.902][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
[2019-10-16 11:12:00.904][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
[2019-10-16 11:12:00.905][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.908][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
[2019-10-16 11:12:00.910][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.925][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
[2019-10-16 11:12:00.926][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.930][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.933][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
[2019-10-16 11:12:00.935][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
[2019-10-16 11:12:00.937][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.939][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.944][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.950][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.953][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
[2019-10-16 11:12:00.954][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.955][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:00.957][main][INFO][org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry][544]:Mapped "{[/channels || /channels.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
[2019-10-16 11:12:01.720][main][INFO][org.springframework.ui.freemarker.SpringTemplateLoader][61]:SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@216914: startup date [Wed Oct 16 11:11:39 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5398edd0] and template loader path [classpath:/templates/]
[2019-10-16 11:12:01.723][main][INFO][org.springframework.web.servlet.view.freemarker.FreeMarkerConfigurer][127]:ClassTemplateLoader for Spring macros added to FreeMarker configuration
[2019-10-16 11:12:03.121][main][INFO][org.springframework.integration.codec.kryo.CompositeKryoRegistrar][74]:configured Kryo registration [40, java.io.File] with serializer org.springframework.integration.codec.kryo.FileSerializer
[2019-10-16 11:12:03.917][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.input' has 1 subscriber(s).
[2019-10-16 11:12:03.920][main][INFO][org.springframework.jmx.export.MBeanExporter][431]:Registering beans for JMX exposure on startup
[2019-10-16 11:12:03.923][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'statFilter' has been autodetected for JMX exposure
[2019-10-16 11:12:03.924][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'dataSource' has been autodetected for JMX exposure
[2019-10-16 11:12:03.940][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'integrationMbeanExporter' has been autodetected for JMX exposure
[2019-10-16 11:12:03.943][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
[2019-10-16 11:12:03.946][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
[2019-10-16 11:12:03.948][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'environmentManager' has been autodetected for JMX exposure
[2019-10-16 11:12:03.950][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'serviceRegistryEndpoint' has been autodetected for JMX exposure
[2019-10-16 11:12:03.952][main][INFO][org.springframework.jmx.export.MBeanExporter][918]:Bean with name 'refreshScope' has been autodetected for JMX exposure
[2019-10-16 11:12:03.959][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
[2019-10-16 11:12:03.987][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'serviceRegistryEndpoint': registering with JMX server as MBean [org.springframework.cloud.client.serviceregistry.endpoint:name=serviceRegistryEndpoint,type=ServiceRegistryEndpoint]
[2019-10-16 11:12:04.000][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
[2019-10-16 11:12:04.037][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'integrationMbeanExporter': registering with JMX server as MBean [org.springframework.integration.monitor:name=integrationMbeanExporter,type=IntegrationMBeanExporter]
[2019-10-16 11:12:04.105][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=216914,type=ConfigurationPropertiesRebinder]
[2019-10-16 11:12:04.112][main][INFO][org.springframework.jmx.export.MBeanExporter][672]:Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
[2019-10-16 11:12:04.117][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
[2019-10-16 11:12:04.125][main][INFO][org.springframework.jmx.export.MBeanExporter][672]:Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
[2019-10-16 11:12:04.139][main][INFO][org.springframework.jmx.export.MBeanExporter][431]:Registering beans for JMX exposure on startup
[2019-10-16 11:12:04.139][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][647]:Registering MessageChannel errorChannel
[2019-10-16 11:12:04.148][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageChannel,name=errorChannel': registering with JMX server as MBean [org.springframework.integration:type=MessageChannel,name=errorChannel]
[2019-10-16 11:12:04.271][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][647]:Registering MessageChannel input
[2019-10-16 11:12:04.274][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageChannel,name=input': registering with JMX server as MBean [org.springframework.integration:type=MessageChannel,name=input]
[2019-10-16 11:12:04.325][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][647]:Registering MessageChannel nullChannel
[2019-10-16 11:12:04.328][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageChannel,name=nullChannel': registering with JMX server as MBean [org.springframework.integration:type=MessageChannel,name=nullChannel]
[2019-10-16 11:12:04.361][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][664]:Registering MessageHandler org.springframework.cloud.stream.binding.StreamListenerMessageHandler@7c48ea9e
[2019-10-16 11:12:04.364][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageHandler,name=org.springframework.cloud.stream.binding.StreamListenerMessageHandler@7c48ea9e,bean=handler': registering with JMX server as MBean [org.springframework.integration:type=MessageHandler,name=org.springframework.cloud.stream.binding.StreamListenerMessageHandler@7c48ea9e,bean=handler]
[2019-10-16 11:12:04.453][main][INFO][org.springframework.integration.monitor.IntegrationMBeanExporter][664]:Registering MessageHandler errorLogger
[2019-10-16 11:12:04.457][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'org.springframework.integration:type=MessageHandler,name=errorLogger,bean=internal': registering with JMX server as MBean [org.springframework.integration:type=MessageHandler,name=errorLogger,bean=internal]
[2019-10-16 11:12:04.486][main][INFO][org.springframework.jmx.export.MBeanExporter][431]:Registering beans for JMX exposure on startup
[2019-10-16 11:12:04.512][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase -2147482648
[2019-10-16 11:12:04.516][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase 0
[2019-10-16 11:12:04.548][main][INFO][org.springframework.cloud.netflix.eureka.InstanceInfoFactory][71]:Setting initial instance status as: STARTING
[2019-10-16 11:12:04.732][main][INFO][com.netflix.discovery.DiscoveryClient][347]:Initializing Eureka in region us-east-1
[2019-10-16 11:12:05.510][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][70]:Using JSON encoding codec LegacyJacksonJson
[2019-10-16 11:12:05.511][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][71]:Using JSON decoding codec LegacyJacksonJson
[2019-10-16 11:12:06.391][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][80]:Using XML encoding codec XStreamXml
[2019-10-16 11:12:06.392][main][INFO][com.netflix.discovery.provider.DiscoveryJerseyProvider][81]:Using XML decoding codec XStreamXml
[2019-10-16 11:12:07.307][main][INFO][com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver][43]:Resolving eureka endpoints via configuration
[2019-10-16 11:12:07.520][main][INFO][com.netflix.discovery.DiscoveryClient][934]:Disable delta property : false
[2019-10-16 11:12:07.521][main][INFO][com.netflix.discovery.DiscoveryClient][935]:Single vip registry refresh property : null
[2019-10-16 11:12:07.521][main][INFO][com.netflix.discovery.DiscoveryClient][936]:Force full registry fetch : false
[2019-10-16 11:12:07.521][main][INFO][com.netflix.discovery.DiscoveryClient][937]:Application is null : false
[2019-10-16 11:12:07.522][main][INFO][com.netflix.discovery.DiscoveryClient][938]:Registered Applications size is zero : true
[2019-10-16 11:12:07.522][main][INFO][com.netflix.discovery.DiscoveryClient][940]:Application version is -1: true
[2019-10-16 11:12:07.522][main][INFO][com.netflix.discovery.DiscoveryClient][1023]:Getting all instance registry info from the eureka server
[2019-10-16 11:12:07.859][main][INFO][com.netflix.discovery.DiscoveryClient][1032]:The response status is 200
[2019-10-16 11:12:07.861][main][INFO][com.netflix.discovery.DiscoveryClient][1258]:Starting heartbeat executor: renew interval is: 30
[2019-10-16 11:12:07.868][main][INFO][com.netflix.discovery.InstanceInfoReplicator][59]:InstanceInfoReplicator onDemand update allowed rate per min is 4
[2019-10-16 11:12:07.874][main][INFO][com.netflix.discovery.DiscoveryClient][434]:Discovery Client initialized at timestamp 1571195527873 with initial instances count: 7
[2019-10-16 11:12:07.907][main][INFO][org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry][40]:Registering application kafkatobase with eureka with status UP
[2019-10-16 11:12:07.910][main][INFO][com.netflix.discovery.DiscoveryClient$3][1293]:Saw local status change event StatusChangeEvent [timestamp=1571195527910, current=UP, previous=STARTING]
[2019-10-16 11:12:07.914][DiscoveryClient-InstanceInfoReplicator-0][INFO][com.netflix.discovery.DiscoveryClient][804]:DiscoveryClient_KAFKATOBASE/10.0.8.217:kafkatobase:8120: registering service...
[2019-10-16 11:12:07.923][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'auditEventsEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=auditEventsEndpoint]
[2019-10-16 11:12:07.963][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'archaiusEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=archaiusEndpoint]
[2019-10-16 11:12:07.986][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'featuresEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=featuresEndpoint]
[2019-10-16 11:12:07.992][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'requestMappingEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=requestMappingEndpoint]
[2019-10-16 11:12:08.009][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'environmentEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=environmentEndpoint]
[2019-10-16 11:12:08.018][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'healthEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=healthEndpoint]
[2019-10-16 11:12:08.025][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'beansEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=beansEndpoint]
[2019-10-16 11:12:08.055][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'infoEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=infoEndpoint]
[2019-10-16 11:12:08.060][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'loggersEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=loggersEndpoint]
[2019-10-16 11:12:08.103][DiscoveryClient-InstanceInfoReplicator-0][INFO][com.netflix.discovery.DiscoveryClient][813]:DiscoveryClient_KAFKATOBASE/10.0.8.217:kafkatobase:8120 - registration status: 204
[2019-10-16 11:12:08.122][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'metricsEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=metricsEndpoint]
[2019-10-16 11:12:08.127][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'traceEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=traceEndpoint]
[2019-10-16 11:12:08.134][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'dumpEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=dumpEndpoint]
[2019-10-16 11:12:08.139][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'autoConfigurationReportEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=autoConfigurationReportEndpoint]
[2019-10-16 11:12:08.148][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'configurationPropertiesReportEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=configurationPropertiesReportEndpoint]
[2019-10-16 11:12:08.154][main][INFO][org.springframework.jmx.export.MBeanExporter][679]:Located managed bean 'channelsEndpoint': registering with JMX server as MBean [org.springframework.boot:type=Endpoint,name=channelsEndpoint]
[2019-10-16 11:12:08.169][main][INFO][org.springframework.integration.endpoint.EventDrivenConsumer][108]:Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
[2019-10-16 11:12:08.169][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.errorChannel' has 1 subscriber(s).
[2019-10-16 11:12:08.170][main][INFO][org.springframework.integration.endpoint.AbstractEndpoint][120]:started _org.springframework.integration.errorLogger
[2019-10-16 11:12:08.170][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase 2147482647
[2019-10-16 11:12:09.062][main][INFO][org.springframework.boot.SpringApplication][597]:The following profiles are active: dev
[2019-10-16 11:12:09.075][main][INFO][org.springframework.context.support.AbstractApplicationContext][583]:Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@78b906d: startup date [Wed Oct 16 11:12:09 CST 2019]; parent: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@216914
[2019-10-16 11:12:09.124][main][INFO][org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor][155]:JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2019-10-16 11:12:09.197][main][INFO][org.springframework.cloud.stream.binder.kafka.config.KafkaBinderConfiguration][155]:AdminUtils selected: Kafka 0.10 AdminUtils
[2019-10-16 11:12:09.388][main][INFO][org.springframework.boot.StartupInfoLogger][57]:Started KafkaToHabseApp in 1.128 seconds (JVM running for 39.839)
[2019-10-16 11:12:09.587][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT
[2019-10-16 11:12:09.588][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:host.name=chance-PC
[2019-10-16 11:12:09.589][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.version=1.8.0_131
[2019-10-16 11:12:09.589][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.vendor=Oracle Corporation
[2019-10-16 11:12:09.589][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre
[2019-10-16 11:12:09.590][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.class.path=D:\workspace-sts-3.9.6.RELEASE\kafkatohbase\target\classes;D:\workspace-sts-3.9.6.RELEASE\wisdom-policing-domain\target\classes;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-stream-kafka\1.3.2.RELEASE\spring-cloud-starter-stream-kafka-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream-binder-kafka\1.3.2.RELEASE\spring-cloud-stream-binder-kafka-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream-binder-kafka-core\1.3.2.RELEASE\spring-cloud-stream-binder-kafka-core-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-kafka\2.1.2.RELEASE\spring-integration-kafka-2.1.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream\1.3.2.RELEASE\spring-cloud-stream-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-actuator\1.5.18.RELEASE\spring-boot-starter-actuator-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-actuator\1.5.18.RELEASE\spring-boot-actuator-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-validation\1.5.18.RELEASE\spring-boot-starter-validation-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-messaging\4.3.21.RELEASE\spring-messaging-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-core\4.3.18.RELEASE\spring-integration-core-4.3.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-jmx\4.3.18.RELEASE\spring-integration-jmx-4.3.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-tuple\1.0.0.RELEASE\spring-tuple-1.0.0.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\integration\spring-integration-tuple\1.0.0.RELEASE\spring-integration-tuple-1.0.0.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\retry\spring-retry\1.2.2.RELEASE\spring-retry-1.2.2.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-stream-codec\1.3.2.RELEASE\spring-cloud-stream-codec-1.3.2.RELEASE.jar;D:\myRepository\m2\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\myRepository\m2\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\myRepository\m2\repository\org\apache\kafka\kafka_2.11\0.10.1.1\kafka_2.11-0.10.1.1.jar;D:\myRepository\m2\repository\net\sf\jopt-simple\jopt-simple\4.9\jopt-simple-4.9.jar;D:\myRepository\m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\myRepository\m2\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\myRepository\m2\repository\com\101tec\zkclient\0.9\zkclient-0.9.jar;D:\myRepository\m2\repository\org\apache\zookeeper\zookeeper\3.4.8\zookeeper-3.4.8.jar;D:\myRepository\m2\repository\io\netty\netty\3.7.0.Final\netty-3.7.0.Final.jar;D:\myRepository\m2\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.4\scala-parser-combinators_2.11-1.0.4.jar;D:\myRepository\m2\repository\org\springframework\kafka\spring-kafka\1.1.8.RELEASE\spring-kafka-1.1.8.RELEASE.jar;D:\myRepository\m2\repository\org\apache\kafka\kafka-clients\0.10.1.0\kafka-clients-0.10.1.0.jar;D:\myRepository\m2\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\myRepository\m2\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\myRepository\m2\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-web\1.5.18.RELEASE\spring-boot-starter-web-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-tomcat\1.5.18.RELEASE\spring-boot-starter-tomcat-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\apache\tomcat\embed\tomcat-embed-core\8.5.35\tomcat-embed-core-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\tomcat-annotations-api\8.5.35\tomcat-annotations-api-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\embed\tomcat-embed-el\8.5.35\tomcat-embed-el-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\8.5.35\tomcat-embed-websocket-8.5.35.jar;D:\myRepository\m2\repository\org\hibernate\hibernate-validator\5.3.6.Final\hibernate-validator-5.3.6.Final.jar;D:\myRepository\m2\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\myRepository\m2\repository\org\jboss\logging\jboss-logging\3.3.2.Final\jboss-logging-3.3.2.Final.jar;D:\myRepository\m2\repository\com\fasterxml\classmate\1.3.4\classmate-1.3.4.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\core\jackson-databind\2.8.11.3\jackson-databind-2.8.11.3.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.8.0\jackson-annotations-2.8.0.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\core\jackson-core\2.8.11\jackson-core-2.8.11.jar;D:\myRepository\m2\repository\org\springframework\spring-web\4.3.21.RELEASE\spring-web-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-aop\4.3.21.RELEASE\spring-aop-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-beans\4.3.21.RELEASE\spring-beans-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-context\4.3.21.RELEASE\spring-context-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-webmvc\4.3.21.RELEASE\spring-webmvc-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-expression\4.3.21.RELEASE\spring-expression-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-eureka\1.4.4.RELEASE\spring-cloud-starter-eureka-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-eureka-client\1.4.4.RELEASE\spring-cloud-starter-netflix-eureka-client-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter\1.3.3.RELEASE\spring-cloud-starter-1.3.3.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-context\1.3.3.RELEASE\spring-cloud-context-1.3.3.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\security\spring-security-crypto\4.2.10.RELEASE\spring-security-crypto-4.2.10.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-commons\1.3.3.RELEASE\spring-cloud-commons-1.3.3.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\security\spring-security-rsa\1.0.3.RELEASE\spring-security-rsa-1.0.3.RELEASE.jar;D:\myRepository\m2\repository\org\bouncycastle\bcpkix-jdk15on\1.55\bcpkix-jdk15on-1.55.jar;D:\myRepository\m2\repository\org\bouncycastle\bcprov-jdk15on\1.55\bcprov-jdk15on-1.55.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-netflix-core\1.4.4.RELEASE\spring-cloud-netflix-core-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-netflix-eureka-client\1.4.4.RELEASE\spring-cloud-netflix-eureka-client-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\com\netflix\eureka\eureka-client\1.7.2\eureka-client-1.7.2.jar;D:\myRepository\m2\repository\org\codehaus\jettison\jettison\1.3.7\jettison-1.3.7.jar;D:\myRepository\m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-eventbus\0.3.0\netflix-eventbus-0.3.0.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-infix\0.3.0\netflix-infix-0.3.0.jar;D:\myRepository\m2\repository\commons-jxpath\commons-jxpath\1.3\commons-jxpath-1.3.jar;D:\myRepository\m2\repository\joda-time\joda-time\2.9.9\joda-time-2.9.9.jar;D:\myRepository\m2\repository\org\antlr\antlr-runtime\3.4\antlr-runtime-3.4.jar;D:\myRepository\m2\repository\org\antlr\stringtemplate\3.2.1\stringtemplate-3.2.1.jar;D:\myRepository\m2\repository\antlr\antlr\2.7.7\antlr-2.7.7.jar;D:\myRepository\m2\repository\com\google\code\gson\gson\2.8.5\gson-2.8.5.jar;D:\myRepository\m2\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;D:\myRepository\m2\repository\com\netflix\archaius\archaius-core\0.7.4\archaius-core-0.7.4.jar;D:\myRepository\m2\repository\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\myRepository\m2\repository\com\netflix\servo\servo-core\0.10.1\servo-core-0.10.1.jar;D:\myRepository\m2\repository\com\netflix\servo\servo-internal\0.10.1\servo-internal-0.10.1.jar;D:\myRepository\m2\repository\com\sun\jersey\jersey-core\1.19.1\jersey-core-1.19.1.jar;D:\myRepository\m2\repository\com\sun\jersey\jersey-client\1.19.1\jersey-client-1.19.1.jar;D:\myRepository\m2\repository\com\sun\jersey\contribs\jersey-apache-client4\1.19.1\jersey-apache-client4-1.19.1.jar;D:\myRepository\m2\repository\org\apache\httpcomponents\httpclient\4.5.6\httpclient-4.5.6.jar;D:\myRepository\m2\repository\org\apache\httpcomponents\httpcore\4.4.10\httpcore-4.4.10.jar;D:\myRepository\m2\repository\com\google\inject\guice\4.1.0\guice-4.1.0.jar;D:\myRepository\m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\myRepository\m2\repository\com\netflix\eureka\eureka-core\1.7.2\eureka-core-1.7.2.jar;D:\myRepository\m2\repository\org\codehaus\woodstox\woodstox-core-asl\4.4.1\woodstox-core-asl-4.4.1.jar;D:\myRepository\m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\myRepository\m2\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-archaius\1.4.4.RELEASE\spring-cloud-starter-netflix-archaius-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\commons-configuration\commons-configuration\1.8\commons-configuration-1.8.jar;D:\myRepository\m2\repository\com\google\guava\guava\18.0\guava-18.0.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-ribbon\1.4.4.RELEASE\spring-cloud-starter-netflix-ribbon-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon\2.2.5\ribbon-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-transport\2.2.5\ribbon-transport-2.2.5.jar;D:\myRepository\m2\repository\io\reactivex\rxnetty-contexts\0.4.9\rxnetty-contexts-0.4.9.jar;D:\myRepository\m2\repository\io\reactivex\rxnetty-servo\0.4.9\rxnetty-servo-0.4.9.jar;D:\myRepository\m2\repository\io\reactivex\rxnetty\0.4.9\rxnetty-0.4.9.jar;D:\myRepository\m2\repository\io\netty\netty-codec-http\4.0.27.Final\netty-codec-http-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-codec\4.0.27.Final\netty-codec-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-handler\4.0.27.Final\netty-handler-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-transport-native-epoll\4.0.27.Final\netty-transport-native-epoll-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-common\4.0.27.Final\netty-common-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-buffer\4.0.27.Final\netty-buffer-4.0.27.Final.jar;D:\myRepository\m2\repository\io\netty\netty-transport\4.0.27.Final\netty-transport-4.0.27.Final.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-core\2.2.5\ribbon-core-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-httpclient\2.2.5\ribbon-httpclient-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-commons-util\0.1.1\netflix-commons-util-0.1.1.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-loadbalancer\2.2.5\ribbon-loadbalancer-2.2.5.jar;D:\myRepository\m2\repository\com\netflix\netflix-commons\netflix-statistics\0.1.1\netflix-statistics-0.1.1.jar;D:\myRepository\m2\repository\io\reactivex\rxjava\1.2.0\rxjava-1.2.0.jar;D:\myRepository\m2\repository\com\netflix\ribbon\ribbon-eureka\2.2.5\ribbon-eureka-2.2.5.jar;D:\myRepository\m2\repository\com\thoughtworks\xstream\xstream\1.4.10\xstream-1.4.10.jar;D:\myRepository\m2\repository\xmlpull\xmlpull\1.1.3.1\xmlpull-1.1.3.1.jar;D:\myRepository\m2\repository\xpp3\xpp3_min\1.1.4c\xpp3_min-1.1.4c.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-eureka-server\1.4.4.RELEASE\spring-cloud-starter-eureka-server-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-eureka-server\1.4.4.RELEASE\spring-cloud-starter-netflix-eureka-server-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-netflix-eureka-server\1.4.4.RELEASE\spring-cloud-netflix-eureka-server-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-freemarker\1.5.18.RELEASE\spring-boot-starter-freemarker-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\freemarker\freemarker\2.3.28\freemarker-2.3.28.jar;D:\myRepository\m2\repository\com\sun\jersey\jersey-server\1.19.1\jersey-server-1.19.1.jar;D:\myRepository\m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-xml\2.8.11\jackson-dataformat-xml-2.8.11.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.8.11\jackson-module-jaxb-annotations-2.8.11.jar;D:\myRepository\m2\repository\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\myRepository\m2\repository\org\ow2\asm\asm\5.0.3\asm-5.0.3.jar;D:\myRepository\m2\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\myRepository\m2\repository\org\springframework\spring-core\4.3.21.RELEASE\spring-core-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\com\alibaba\druid-spring-boot-starter\1.1.10\druid-spring-boot-starter-1.1.10.jar;D:\myRepository\m2\repository\com\alibaba\druid\1.1.10\druid-1.1.10.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-autoconfigure\1.5.18.RELEASE\spring-boot-autoconfigure-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\mysql\mysql-connector-java\5.1.47\mysql-connector-java-5.1.47.jar;D:\myRepository\m2\repository\com\github\pagehelper\pagehelper-spring-boot-starter\1.2.5\pagehelper-spring-boot-starter-1.2.5.jar;D:\myRepository\m2\repository\com\github\pagehelper\pagehelper-spring-boot-autoconfigure\1.2.5\pagehelper-spring-boot-autoconfigure-1.2.5.jar;D:\myRepository\m2\repository\com\github\pagehelper\pagehelper\5.1.4\pagehelper-5.1.4.jar;D:\myRepository\m2\repository\com\github\jsqlparser\jsqlparser\1.0\jsqlparser-1.0.jar;D:\myRepository\m2\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\1.3.2\mybatis-spring-boot-starter-1.3.2.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-jdbc\1.5.18.RELEASE\spring-boot-starter-jdbc-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\apache\tomcat\tomcat-jdbc\8.5.35\tomcat-jdbc-8.5.35.jar;D:\myRepository\m2\repository\org\apache\tomcat\tomcat-juli\8.5.35\tomcat-juli-8.5.35.jar;D:\myRepository\m2\repository\org\springframework\spring-jdbc\4.3.21.RELEASE\spring-jdbc-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\1.3.2\mybatis-spring-boot-autoconfigure-1.3.2.jar;D:\myRepository\m2\repository\org\mybatis\mybatis\3.4.6\mybatis-3.4.6.jar;D:\myRepository\m2\repository\org\mybatis\mybatis-spring\1.3.2\mybatis-spring-1.3.2.jar;D:\myRepository\m2\repository\com\eversec\ebp\system\system-feignclient\1.1.0\system-feignclient-1.1.0.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-ribbon\1.4.4.RELEASE\spring-cloud-starter-ribbon-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-feign\1.4.4.RELEASE\spring-cloud-starter-feign-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-openfeign\1.4.4.RELEASE\spring-cloud-starter-openfeign-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\io\github\openfeign\feign-core\9.5.0\feign-core-9.5.0.jar;D:\myRepository\m2\repository\org\jvnet\animal-sniffer-annotation\1.0\animal-sniffer-annotation-1.0.jar;D:\myRepository\m2\repository\io\github\openfeign\feign-slf4j\9.5.0\feign-slf4j-9.5.0.jar;D:\myRepository\m2\repository\io\github\openfeign\feign-hystrix\9.5.0\feign-hystrix-9.5.0.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-hystrix\1.4.4.RELEASE\spring-cloud-starter-hystrix-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\cloud\spring-cloud-starter-netflix-hystrix\1.4.4.RELEASE\spring-cloud-starter-netflix-hystrix-1.4.4.RELEASE.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-core\1.5.12\hystrix-core-1.5.12.jar;D:\myRepository\m2\repository\org\hdrhistogram\HdrHistogram\2.1.9\HdrHistogram-2.1.9.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-metrics-event-stream\1.5.12\hystrix-metrics-event-stream-1.5.12.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-serialization\1.5.12\hystrix-serialization-1.5.12.jar;D:\myRepository\m2\repository\com\fasterxml\jackson\module\jackson-module-afterburner\2.8.11\jackson-module-afterburner-2.8.11.jar;D:\myRepository\m2\repository\com\netflix\hystrix\hystrix-javanica\1.5.12\hystrix-javanica-1.5.12.jar;D:\myRepository\m2\repository\org\aspectj\aspectjweaver\1.8.13\aspectjweaver-1.8.13.jar;D:\myRepository\m2\repository\com\eversec\framework\eversec-web\1.0.0-SNAPSHOT\eversec-web-1.0.0-SNAPSHOT.jar;D:\myRepository\m2\repository\com\eversec\framework\eversec-core\1.0.0-SNAPSHOT\eversec-core-1.0.0-SNAPSHOT.jar;D:\myRepository\m2\repository\com\alibaba\fastjson\1.2.58\fastjson-1.2.58.jar;D:\myRepository\m2\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;D:\myRepository\m2\repository\xml-apis\xml-apis\1.4.01\xml-apis-1.4.01.jar;D:\myRepository\m2\repository\jaxen\jaxen\1.1.6\jaxen-1.1.6.jar;D:\myRepository\m2\repository\com\eversec\framework\eversec-commons\1.0.0-SNAPSHOT\eversec-commons-1.0.0-SNAPSHOT.jar;D:\myRepository\m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\myRepository\m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\myRepository\m2\repository\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\myRepository\m2\repository\commons-codec\commons-codec\1.10\commons-codec-1.10.jar;D:\myRepository\m2\repository\io\springfox\springfox-swagger-ui\2.7.0\springfox-swagger-ui-2.7.0.jar;D:\myRepository\m2\repository\io\springfox\springfox-spring-web\2.7.0\springfox-spring-web-2.7.0.jar;D:\myRepository\m2\repository\org\reflections\reflections\0.9.11\reflections-0.9.11.jar;D:\myRepository\m2\repository\org\javassist\javassist\3.21.0-GA\javassist-3.21.0-GA.jar;D:\myRepository\m2\repository\io\springfox\springfox-swagger2\2.7.0\springfox-swagger2-2.7.0.jar;D:\myRepository\m2\repository\io\swagger\swagger-models\1.5.13\swagger-models-1.5.13.jar;D:\myRepository\m2\repository\io\springfox\springfox-spi\2.7.0\springfox-spi-2.7.0.jar;D:\myRepository\m2\repository\io\springfox\springfox-core\2.7.0\springfox-core-2.7.0.jar;D:\myRepository\m2\repository\net\bytebuddy\byte-buddy\1.6.14\byte-buddy-1.6.14.jar;D:\myRepository\m2\repository\io\springfox\springfox-schema\2.7.0\springfox-schema-2.7.0.jar;D:\myRepository\m2\repository\io\springfox\springfox-swagger-common\2.7.0\springfox-swagger-common-2.7.0.jar;D:\myRepository\m2\repository\org\springframework\plugin\spring-plugin-core\1.2.0.RELEASE\spring-plugin-core-1.2.0.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\plugin\spring-plugin-metadata\1.2.0.RELEASE\spring-plugin-metadata-1.2.0.RELEASE.jar;D:\myRepository\m2\repository\org\mapstruct\mapstruct\1.1.0.Final\mapstruct-1.1.0.Final.jar;D:\myRepository\m2\repository\com\eversec\ebp\system\system-api\1.1.0\system-api-1.1.0.jar;D:\myRepository\m2\repository\org\hibernate\javax\persistence\hibernate-jpa-2.1-api\1.0.0.Final\hibernate-jpa-2.1-api-1.0.0.Final.jar;D:\myRepository\m2\repository\io\swagger\swagger-annotations\1.5.13\swagger-annotations-1.5.13.jar;D:\myRepository\m2\repository\org\apache\commons\commons-lang3\3.8.1\commons-lang3-3.8.1.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-log4j2\1.5.18.RELEASE\spring-boot-starter-log4j2-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-slf4j-impl\2.7\log4j-slf4j-impl-2.7.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-api\2.7\log4j-api-2.7.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-core\2.7\log4j-core-2.7.jar;D:\myRepository\m2\repository\org\slf4j\jcl-over-slf4j\1.7.25\jcl-over-slf4j-1.7.25.jar;D:\myRepository\m2\repository\org\slf4j\jul-to-slf4j\1.7.25\jul-to-slf4j-1.7.25.jar;D:\myRepository\m2\repository\com\lmax\disruptor\3.3.8\disruptor-3.3.8.jar;D:\myRepository\m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter-data-redis\1.5.18.RELEASE\spring-boot-starter-data-redis-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\data\spring-data-redis\1.8.17.RELEASE\spring-data-redis-1.8.17.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\data\spring-data-keyvalue\1.2.17.RELEASE\spring-data-keyvalue-1.2.17.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\data\spring-data-commons\1.13.17.RELEASE\spring-data-commons-1.13.17.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-tx\4.3.21.RELEASE\spring-tx-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-oxm\4.3.21.RELEASE\spring-oxm-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\spring-context-support\4.3.21.RELEASE\spring-context-support-4.3.21.RELEASE.jar;D:\myRepository\m2\repository\redis\clients\jedis\2.9.0\jedis-2.9.0.jar;D:\myRepository\m2\repository\org\apache\commons\commons-pool2\2.4.3\commons-pool2-2.4.3.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot-starter\1.5.18.RELEASE\spring-boot-starter-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\springframework\boot\spring-boot\1.5.18.RELEASE\spring-boot-1.5.18.RELEASE.jar;D:\myRepository\m2\repository\org\yaml\snakeyaml\1.17\snakeyaml-1.17.jar;D:\myRepository\m2\repository\org\apache\logging\log4j\log4j-web\2.10.0\log4j-web-2.10.0.jar;D:\software\sts-bundle\sts-3.9.6.RELEASE\configuration\org.eclipse.osgi\324\0\.cp\lib\javaagent-shaded.jar
[2019-10-16 11:12:09.594][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Java\jdk1.8.0_131\jre\bin;C:/Program Files/Java/jdk1.8.0_131/bin/../jre/bin/server;C:/Program Files/Java/jdk1.8.0_131/bin/../jre/bin;C:/Program Files/Java/jdk1.8.0_131/bin/../jre/lib/amd64;C:\Python\Python37-32\Scripts\;C:\Python\Python37-32\;C:\Program Files\Java\jdk1.8.0_131\bin;C:\ProgramData\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Lenovo\Fingerprint Manager Pro\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\apache-maven-3.6.0\bin;C:\Program Files\nodejs\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\MySQL\MySQL Server 5.5\bin;C:\Program Files\IDM Computer Solutions\UltraEdit;C:\Program Files\Pandoc\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Microsoft VS Code Insiders\bin;C:\Users\eversec\AppData\Roaming\npm;D:\software\sts-bundle\sts-3.9.6.RELEASE;;.
[2019-10-16 11:12:09.594][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.io.tmpdir=C:\Users\eversec\AppData\Local\Temp\
[2019-10-16 11:12:09.595][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:java.compiler=<NA>
[2019-10-16 11:12:09.595][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:os.name=Windows 7
[2019-10-16 11:12:09.596][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:os.arch=amd64
[2019-10-16 11:12:09.596][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:os.version=6.1
[2019-10-16 11:12:09.596][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:user.name=eversec
[2019-10-16 11:12:09.596][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:user.home=C:\Users\eversec
[2019-10-16 11:12:09.597][main][INFO][org.apache.zookeeper.Environment][100]:Client environment:user.dir=D:\workspace-sts-3.9.6.RELEASE\kafkatohbase
[2019-10-16 11:12:09.599][main][INFO][org.apache.zookeeper.ZooKeeper][438]:Initiating client connection, connectString=10.0.10.43:2181,10.0.10.44:2181,10.0.10.45:2181 sessionTimeout=10000 watcher=org.I0Itec.zkclient.ZkClient@5e6d2502
[2019-10-16 11:12:09.685][main-SendThread(10.0.10.43:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1032]:Opening socket connection to server 10.0.10.43/10.0.10.43:2181. Will not attempt to authenticate using SASL (unknown error)
[2019-10-16 11:12:09.689][main-SendThread(10.0.10.43:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][876]:Socket connection established to 10.0.10.43/10.0.10.43:2181, initiating session
[2019-10-16 11:12:09.783][main-SendThread(10.0.10.43:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1299]:Session establishment complete on server 10.0.10.43/10.0.10.43:2181, sessionid = 0x16dcec221050ca5, negotiated timeout = 10000
[2019-10-16 11:12:11.208][main][INFO][org.apache.zookeeper.ZooKeeper][684]:Session: 0x16dcec221050ca5 closed
[2019-10-16 11:12:11.209][main-EventThread][INFO][org.apache.zookeeper.ClientCnxn$EventThread][519]:EventThread shut down for session: 0x16dcec221050ca5
[2019-10-16 11:12:11.213][main][INFO][org.apache.zookeeper.ZooKeeper][438]:Initiating client connection, connectString=10.0.10.43:2181,10.0.10.44:2181,10.0.10.45:2181 sessionTimeout=10000 watcher=org.I0Itec.zkclient.ZkClient@23ddf8e5
[2019-10-16 11:12:11.235][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1032]:Opening socket connection to server 10.0.10.44/10.0.10.44:2181. Will not attempt to authenticate using SASL (unknown error)
[2019-10-16 11:12:11.284][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][876]:Socket connection established to 10.0.10.44/10.0.10.44:2181, initiating session
[2019-10-16 11:12:11.305][main-SendThread(10.0.10.44:2181)][INFO][org.apache.zookeeper.ClientCnxn$SendThread][1299]:Session establishment complete on server 10.0.10.44/10.0.10.44:2181, sessionid = 0x26dcec562cf000e, negotiated timeout = 10000
[2019-10-16 11:12:11.731][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-hello-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:12:11.748][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-hello-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:12:11.829][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:12:11.830][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:12:12.042][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.hello.test-hello-group.errors' has 1 subscriber(s).
[2019-10-16 11:12:12.044][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.hello.test-hello-group.errors' has 0 subscriber(s).
[2019-10-16 11:12:12.045][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.hello.test-hello-group.errors' has 1 subscriber(s).
[2019-10-16 11:12:12.045][main][INFO][org.springframework.integration.channel.AbstractSubscribableChannel][81]:Channel 'kafkatobase:dev:8120.hello.test-hello-group.errors' has 2 subscriber(s).
[2019-10-16 11:12:12.060][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-hello-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:12:12.061][main][INFO][org.apache.kafka.common.config.AbstractConfig][180]:ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [10.0.10.43:6667, 10.0.10.44:6667, 10.0.10.45:6667]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-hello-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-10-16 11:12:12.071][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][83]:Kafka version : 0.10.1.0
[2019-10-16 11:12:12.072][main][INFO][org.apache.kafka.common.utils.AppInfoParser$AppInfo][84]:Kafka commitId : 3402a74efb23d1d4
[2019-10-16 11:12:12.081][main][INFO][org.springframework.integration.endpoint.AbstractEndpoint][120]:started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@3d2abb1
[2019-10-16 11:12:12.084][main][INFO][org.springframework.integration.endpoint.EventDrivenConsumer][108]:Adding {message-handler:inbound.hello.test-hello-group} as a subscriber to the 'bridge.hello' channel
[2019-10-16 11:12:12.085][main][INFO][org.springframework.integration.endpoint.AbstractEndpoint][120]:started inbound.hello.test-hello-group
[2019-10-16 11:12:12.087][main][INFO][org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup][345]:Starting beans in phase 2147483647
[2019-10-16 11:12:12.150][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Starting ProtocolHandler ["http-nio-8120"]
[2019-10-16 11:12:12.173][main][INFO][org.apache.juli.logging.DirectJDKLog][180]:Using a shared selector for servlet write/read
[2019-10-16 11:12:12.194][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$GroupCoordinatorResponseHandler][555]:Discovered coordinator 10.0.10.44:6667 (id: 2147482645 rack: null) for group test-hello-group.
[2019-10-16 11:12:12.202][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group test-hello-group
[2019-10-16 11:12:12.206][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:12:12.206][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group test-hello-group
[2019-10-16 11:12:12.283][main][INFO][org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer][216]:Tomcat started on port(s): 8120 (http)
[2019-10-16 11:12:12.285][main][INFO][org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration][124]:Updating port to 8120
[2019-10-16 11:12:12.293][main][INFO][org.springframework.boot.StartupInfoLogger][57]:Started KafkaToHabseApp in 38.161 seconds (JVM running for 42.745)
[2019-10-16 11:12:15.514][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group test-hello-group with generation 5
[2019-10-16 11:12:15.519][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [hello-0] for group test-hello-group
[2019-10-16 11:12:15.649][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[hello-0]
[2019-10-16 11:12:52.509][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [hello-0] for group test-hello-group
[2019-10-16 11:12:53.075][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[hello-0]
[2019-10-16 11:12:53.076][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group test-hello-group
[2019-10-16 11:12:53.104][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group test-hello-group with generation 6
[2019-10-16 11:12:53.105][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [] for group test-hello-group
[2019-10-16 11:12:53.105][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[]
[2019-10-16 11:17:07.531][AsyncResolver-bootstrap-executor-0][INFO][com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver][43]:Resolving eureka endpoints via configuration
[2019-10-16 11:17:12.207][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][333]:Revoking previously assigned partitions [] for group test-hello-group
[2019-10-16 11:17:12.208][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][250]:partitions revoked:[]
[2019-10-16 11:17:12.208][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator][381]:(Re-)joining group test-hello-group
[2019-10-16 11:17:14.436][-C-1][INFO][org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1][349]:Successfully joined group test-hello-group with generation 7
[2019-10-16 11:17:14.437][-C-1][INFO][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator][225]:Setting newly assigned partitions [hello-10, hello-11, hello-18, hello-19, hello-16, hello-17, hello-14, hello-15, hello-12, hello-13] for group test-hello-group
[2019-10-16 11:17:14.602][-C-1][INFO][org.springframework.kafka.listener.AbstractMessageListenerContainer$2][255]:partitions assigned:[hello-10, hello-11, hello-18, hello-19, hello-16, hello-17, hello-14, hello-15, hello-12, hello-13]
